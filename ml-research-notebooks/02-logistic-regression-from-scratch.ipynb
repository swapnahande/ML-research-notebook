{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d11f3e",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Logistic Regression from Scratch\n",
    "In this notebook, we will:\n",
    "- Generate binary classification data\n",
    "- Implement logistic regression using Binary Cross Entropy\n",
    "- Train using Gradient Descent\n",
    "- Visualize the decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a89e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='bwr')\n",
    "plt.title('Classification Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fc440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "weights = np.random.randn(3,1)\n",
    "learning_rate = 0.1\n",
    "losses = []\n",
    "\n",
    "for i in range(1000):\n",
    "    z = X_b.dot(weights)\n",
    "    h = sigmoid(z)\n",
    "    loss = -np.mean(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "    gradient = X_b.T.dot(h - y) / y.size\n",
    "    weights -= learning_rate * gradient\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb8196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.plot(losses)\n",
    "plt.title('Binary Cross Entropy Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1e7010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Boundary\n",
    "x1 = np.linspace(X[:,0].min(), X[:,0].max(), 100)\n",
    "x2 = -(weights[0] + weights[1]*x1)/weights[2]\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1], c=y.ravel(), cmap='bwr')\n",
    "plt.plot(x1, x2, color='black')\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
